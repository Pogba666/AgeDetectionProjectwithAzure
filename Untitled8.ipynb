{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "38b2dSz0alAC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from keras.models import Sequential,load_model,Model\n",
        "from keras.layers import Conv2D,MaxPool2D,Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wAlR9rEcZZ8"
      },
      "source": [
        "fldr = os.getcwd() + '/data'\n",
        "files=os.listdir(fldr)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy_HvUZvcZdQ",
        "outputId": "442db046-8de0-4cdd-b4a6-15893d96d66e"
      },
      "source": [
        "pixels = []\n",
        "age = []\n",
        "gender = []\n",
        "import os\n",
        "\n",
        "for img in files:\n",
        "  ages = img.split(\"_\")[0]\n",
        "  genders = img.split(\"_\")[1]\n",
        "  total=fldr+'/'+img\n",
        "  print(total)\n",
        "  img = cv2.imread(total)\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  pixels.append(np.array(img))\n",
        "  age.append(np.array(ages))\n",
        "  gender.append(np.array(genders))\n",
        "age = np.array(age,dtype=np.int64)\n",
        "pixels = np.array(pixels)\n",
        "gender = np.array(gender,dtype=np.uint64)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/26_1_0_20170104165749289.jpg\n",
            "/content/data/26_0_2_20170104023216134.jpg\n",
            "/content/data/26_1_3_20170104222745511.jpg\n",
            "/content/data/26_1_2_20170104020934116.jpg\n",
            "/content/data/26_1_0_20170103182040225.jpg\n",
            "/content/data/26_1_0_20170103180235712.jpg\n",
            "/content/data/26_0_3_20170104230301625.jpg\n",
            "/content/data/26_1_0_20170109132910372.jpg\n",
            "/content/data/26_1_3_20170104222929063.jpg\n",
            "/content/data/26_0_1_20170103210459306.jpg\n",
            "/content/data/26_1_0_20170105002839534.jpg\n",
            "/content/data/26_1_3_20170104214236981.jpg\n",
            "/content/data/26_1_0_20170104235427939.jpg\n",
            "/content/data/26_1_1_20170104235433201.jpg\n",
            "/content/data/26_1_3_20170104223033351.jpg\n",
            "/content/data/26_0_3_20170104214726725.jpg\n",
            "/content/data/26_1_2_20170104021717909.jpg\n",
            "/content/data/26_1_0_20170104022111485.jpg\n",
            "/content/data/26_1_3_20170104223022663.jpg\n",
            "/content/data/26_1_3_20170104222627929.jpg\n",
            "/content/data/26_1_2_20170104021513981.jpg\n",
            "/content/data/26_1_0_20170105183935352.jpg\n",
            "/content/data/26_1_3_20170104222955855.jpg\n",
            "/content/data/26_1_2_20170105164540403.jpg\n",
            "/content/data/26_0_4_20170103235432764.jpg\n",
            "/content/data/26_1_2_20170104022833734.jpg\n",
            "/content/data/26_1_0_20170104165807080.jpg\n",
            "/content/data/26_1_0_20170103181948785.jpg\n",
            "/content/data/26_0_3_20170104230258265.jpg\n",
            "/content/data/26_0_2_20170104201313859.jpg\n",
            "/content/data/26_0_3_20170104230413577.jpg\n",
            "/content/data/26_1_3_20170104222936409.jpg\n",
            "/content/data/26_1_3_20170104222939159.jpg\n",
            "/content/data/26_0_2_20161219191301043.jpg\n",
            "/content/data/26_1_2_20170103181524137.jpg\n",
            "/content/data/26_1_2_20170105163925349.jpg\n",
            "/content/data/26_1_3_20170104232435586.jpg\n",
            "/content/data/26_1_0_20170105163250483.jpg\n",
            "/content/data/26_1_2_20170105163951372.jpg\n",
            "/content/data/26_1_3_20170104222805519.jpg\n",
            "/content/data/26_1_3_20170104214715278.jpg\n",
            "/content/data/26_0_2_20170104022626733.jpg\n",
            "/content/data/26_1_0_20170104021504132.jpg\n",
            "/content/data/26_1_0_20170105003228731.jpg\n",
            "/content/data/26_0_0_20170105162452859.jpg\n",
            "/content/data/26_1_3_20170104232333226.jpg\n",
            "/content/data/26_0_4_20170103235258756.jpg\n",
            "/content/data/26_1_3_20170104223100991.jpg\n",
            "/content/data/26_0_3_20170104232129634.jpg\n",
            "/content/data/26_1_0_20170103180546928.jpg\n",
            "/content/data/26_1_2_20170104022244853.jpg\n",
            "/content/data/26_0_2_20170104022540590.jpg\n",
            "/content/data/26_0_2_20170104020643628.jpg\n",
            "/content/data/26_1_0_20170103180649464.jpg\n",
            "/content/data/26_1_3_20170104222813183.jpg\n",
            "/content/data/26_1_2_20170104015741532.jpg\n",
            "/content/data/26_1_3_20170104222725472.jpg\n",
            "/content/data/26_0_3_20170104230323233.jpg\n",
            "/content/data/26_1_2_20170109213532617.jpg\n",
            "/content/data/26_0_4_20170103235338373.jpg\n",
            "/content/data/26_1_0_20170105183657951.jpg\n",
            "/content/data/26_0_3_20170104230341769.jpg\n",
            "/content/data/26_1_1_20170103181834825.jpg\n",
            "/content/data/26_1_1_20170103225852672.jpg\n",
            "/content/data/26_1_3_20170104214731389.jpg\n",
            "/content/data/26_0_4_20170103235333148.jpg\n",
            "/content/data/26_1_0_20170103182456297.jpg\n",
            "/content/data/26_0_4_20170103235233157.jpg\n",
            "/content/data/26_1_0_20170105183644799.jpg\n",
            "/content/data/26_0_0_20170104230456289.jpg\n",
            "/content/data/26_0_2_20170103181248536.jpg\n",
            "/content/data/26_1_3_20161220222108978.jpg\n",
            "/content/data/26_1_2_20170104022817638.jpg\n",
            "/content/data/26_0_4_20170103235523972.jpg\n",
            "/content/data/26_1_0_20170103182026289.jpg\n",
            "/content/data/26_0_1_20170103235317796.jpg\n",
            "/content/data/26_1_0_20170103213110260.jpg\n",
            "/content/data/26_0_0_20170105183712607.jpg\n",
            "/content/data/26_0_4_20170103224832945.jpg\n",
            "/content/data/26_0_1_20170103181054528.jpg\n",
            "/content/data/26_0_3_20170104230509745.jpg\n",
            "/content/data/26_1_3_20170104231407282.jpg\n",
            "/content/data/26_0_0_20170105164133579.jpg\n",
            "/content/data/26_1_0_20170103181901521.jpg\n",
            "/content/data/26_0_1_20170103180959080.jpg\n",
            "/content/data/26_1_3_20170104232120449.jpg\n",
            "/content/data/26_0_4_20170105162624331.jpg\n",
            "/content/data/26_1_0_20170103224921463.jpg\n",
            "/content/data/26_1_3_20170104232150859.jpg\n",
            "/content/data/26_0_0_20170105162648388.jpg\n",
            "/content/data/26_1_0_20170104021254429.jpg\n",
            "/content/data/26_1_0_20170109134235854.jpg\n",
            "/content/data/26_1_2_20170109012525167.jpg\n",
            "/content/data/26_0_0_20170104201228553.jpg\n",
            "/content/data/26_0_4_20170103235020885.jpg\n",
            "/content/data/26_1_0_20170103180530224.jpg\n",
            "/content/data/26_0_3_20170104214717941.jpg\n",
            "/content/data/26_0_3_20170104230513064.jpg\n",
            "/content/data/26_1_0_20170103235707476.jpg\n",
            "/content/data/26_1_2_20170104015910819.jpg\n",
            "/content/data/26_1_0_20170104022424245.jpg\n",
            "/content/data/26_0_0_20170105163435235.jpg\n",
            "/content/data/26_1_3_20170104223130527.jpg\n",
            "/content/data/26_1_2_20170105161510388.jpg\n",
            "/content/data/26_1_2_20170103184117683.jpg\n",
            "/content/data/26_1_2_20170104022148861.jpg\n",
            "/content/data/26_1_3_20170104222943143.jpg\n",
            "/content/data/26_1_3_20170104222933607.jpg\n",
            "/content/data/26_0_3_20170104230305945.jpg\n",
            "/content/data/26_0_4_20170103214633693.jpg\n",
            "/content/data/26_1_0_20170104021534429.jpg\n",
            "/content/data/26_1_3_20170104222621671.jpg\n",
            "/content/data/26_0_4_20170103235546910.jpg\n",
            "/content/data/26_1_3_20170104222850687.jpg\n",
            "/content/data/26_1_2_20170104021834541.jpg\n",
            "/content/data/26_1_0_20170103175557343.jpg\n",
            "/content/data/26_0_3_20170104215715094.jpg\n",
            "/content/data/26_0_4_20170105163503003.jpg\n",
            "/content/data/26_1_3_20170104232408872.jpg\n",
            "/content/data/26_1_0_20170109002353702.jpg\n",
            "/content/data/26_0_3_20170104230403674.jpg\n",
            "/content/data/26_1_2_20170109002645487.jpg\n",
            "/content/data/26_1_0_20170103181326336.jpg\n",
            "/content/data/26_1_2_20170104020703028.jpg\n",
            "/content/data/26_0_3_20170105175423430.jpg\n",
            "/content/data/26_0_2_20170109001126902.jpg\n",
            "/content/data/26_0_3_20170104230356601.jpg\n",
            "/content/data/26_0_3_20170105175308269.jpg\n",
            "/content/data/26_1_3_20170104222740327.jpg\n",
            "/content/data/26_1_3_20170104223139599.jpg\n",
            "/content/data/26_0_3_20170104214630381.jpg\n",
            "/content/data/26_1_1_20170103181931657.jpg\n",
            "/content/data/26_1_0_20170110173815028.jpg\n",
            "/content/data/26_0_4_20170108224531895.jpg\n",
            "/content/data/26_1_3_20170104232139409.jpg\n",
            "/content/data/26_0_4_20170103235427740.jpg\n",
            "/content/data/26_1_3_20170104223133454.jpg\n",
            "/content/data/26_1_0_20170103181112840.jpg\n",
            "/content/data/26_1_3_20170104222922568.jpg\n",
            "/content/data/26_1_1_20170103181439968.jpg\n",
            "/content/data/26_0_3_20170104232246706.jpg\n",
            "/content/data/26_0_3_20170104214719799.jpg\n",
            "/content/data/26_0_2_20170105163936652.jpg\n",
            "/content/data/26_0_3_20170104214448709.jpg\n",
            "/content/data/26_1_3_20170104232413655.jpg\n",
            "/content/data/26_0_4_20170103235645596.jpg\n",
            "/content/data/26_1_3_20170104220140542.jpg\n",
            "/content/data/26_0_3_20170104230310913.jpg\n",
            "/content/data/26_0_2_20170104022441117.jpg\n",
            "/content/data/26_1_1_20170109134519311.jpg\n",
            "/content/data/26_1_0_20170103181940954.jpg\n",
            "/content/data/26_0_1_20170104230506569.jpg\n",
            "/content/data/26_1_3_20170104232329458.jpg\n",
            "/content/data/26_1_2_20170104022829221.jpg\n",
            "/content/data/26_0_4_20170103235429853.jpg\n",
            "/content/data/26_1_0_20170104235143076.jpg\n",
            "/content/data/26_1_0_20170103181710200.jpg\n",
            "/content/data/26_1_0_20170103181852617.jpg\n",
            "/content/data/26_1_0_20170103181926881.jpg\n",
            "/content/data/26_1_0_20170105163517523.jpg\n",
            "/content/data/26_1_2_20170104020230700.jpg\n",
            "/content/data/26_1_0_20170109141214949.jpg\n",
            "/content/data/26_0_3_20170104232208944.jpg\n",
            "/content/data/26_0_4_20170103235609892.jpg\n",
            "/content/data/26_0_3_20170104230427081.jpg\n",
            "/content/data/26_1_0_20170111182452795.jpg\n",
            "/content/data/26_0_2_20170104023102422.jpg\n",
            "/content/data/26_1_3_20170104215700398.jpg\n",
            "/content/data/26_0_1_20170105183720623.jpg\n",
            "/content/data/26_1_2_20170104022154229.jpg\n",
            "/content/data/26_1_2_20170109002657161.jpg\n",
            "/content/data/26_1_3_20170104223140343.jpg\n",
            "/content/data/26_1_2_20170104022654101.jpg\n",
            "/content/data/26_1_3_20170104232131633.jpg\n",
            "/content/data/26_0_0_20170108235818665.jpg\n",
            "/content/data/26_0_3_20170104230400274.jpg\n",
            "/content/data/26_0_3_20170104230250721.jpg\n",
            "/content/data/26_1_0_20170103180946896.jpg\n",
            "/content/data/26_1_0_20170109002602686.jpg\n",
            "/content/data/26_1_3_20170104232420017.jpg\n",
            "/content/data/26_1_2_20170104020149844.jpg\n",
            "/content/data/26_1_0_20170105183649031.jpg\n",
            "/content/data/26_1_3_20170104223054575.jpg\n",
            "/content/data/26_1_3_20170104215719454.jpg\n",
            "/content/data/26_1_3_20170104222855375.jpg\n",
            "/content/data/26_0_4_20170103235328516.jpg\n",
            "/content/data/26_0_1_20170105183731642.jpg\n",
            "/content/data/26_1_3_20170104222823975.jpg\n",
            "/content/data/26_0_4_20170104165424576.jpg\n",
            "/content/data/26_0_0_20170104230421569.jpg\n",
            "/content/data/26_0_3_20170104215431446.jpg\n",
            "/content/data/26_0_3_20170104230325016.jpg\n",
            "/content/data/26_0_1_20170104170637953.jpg\n",
            "/content/data/26_1_3_20170104222810087.jpg\n",
            "/content/data/26_1_3_20170104222600591.jpg\n",
            "/content/data/26_1_0_20170103181123449.jpg\n",
            "/content/data/26_1_2_20161219204400164.jpg\n",
            "/content/data/26_1_3_20170104215629245.jpg\n",
            "/content/data/26_1_3_20170104223003860.jpg\n",
            "/content/data/26_0_4_20170103235404028.jpg\n",
            "/content/data/26_1_0_20170104233850235.jpg\n",
            "/content/data/26_0_4_20170104200600267.jpg\n",
            "/content/data/26_0_1_20170105183906447.jpg\n",
            "/content/data/26_1_3_20170104215610550.jpg\n",
            "/content/data/26_1_3_20170104222736351.jpg\n",
            "/content/data/26_1_3_20170104222841167.jpg\n",
            "/content/data/26_0_3_20170104230424841.jpg\n",
            "/content/data/26_1_3_20161220221501954.jpg\n",
            "/content/data/26_0_4_20170104170011130.jpg\n",
            "/content/data/26_0_2_20170104015801932.jpg\n",
            "/content/data/26_1_0_20170103234817732.jpg\n",
            "/content/data/26_0_4_20170103224903432.jpg\n",
            "/content/data/26_1_3_20170104223128119.jpg\n",
            "/content/data/26_1_2_20170104022229597.jpg\n",
            "/content/data/26_1_2_20170104022532727.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfmkDnYgcZkF"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(pixels,age,random_state=100)\n",
        "x_train_2,x_test_2,y_train_2,y_test_2 = train_test_split(pixels,gender,random_state=100)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "Hr6MXeEKawaA",
        "outputId": "c793782b-d904-4ad7-fde9-197e1ebed1f7"
      },
      "source": [
        "\n",
        "input = Input(shape=(200,200,3))\n",
        "conv1 = Conv2D(140,(3,3),activation=\"relu\")(input)\n",
        "conv2 = Conv2D(130,(3,3),activation=\"relu\")(conv1)\n",
        "batch1 = BatchNormalization()(conv2)\n",
        "pool3 = MaxPool2D((2,2))(batch1)\n",
        "conv3 = Conv2D(120,(3,3),activation=\"relu\")(pool3)\n",
        "batch2 = BatchNormalization()(conv3)\n",
        "pool4 = MaxPool2D((2,2))(batch2)\n",
        "flt = Flatten()(pool4)\n",
        "#age\n",
        "age_l = Dense(128,activation=\"relu\")(flt)\n",
        "age_l = Dense(64,activation=\"relu\")(age_l)\n",
        "age_l = Dense(32,activation=\"relu\")(age_l)\n",
        "age_l = Dense(1,activation=\"relu\")(age_l)\n",
        "#gender\n",
        "gender_l = Dense(128,activation=\"relu\")(flt)\n",
        "gender_l = Dense(80,activation=\"relu\")(gender_l)\n",
        "gender_l = Dense(64,activation=\"relu\")(gender_l)\n",
        "gender_l = Dense(32,activation=\"relu\")(gender_l)\n",
        "gender_l = Dropout(0.5)(gender_l)\n",
        "gender_l = Dense(2,activation=\"softmax\")(gender_l)\n",
        "\n",
        "model = Model(inputs=[input],outputs=[age_l,gender_l])\n",
        "model.compile(optimizer=\"adam\",loss=[\"mse\",\"sparse_categorical_crossentropy\"],metrics=['mae','accuracy'])\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-4bd5404d8d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mgender_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mage_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgender_l\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: call() got an unexpected keyword argument 'outputs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzQpWn4-x7ki"
      },
      "source": [
        "save = model.fit(x_train,[y_train,y_train_2],validation_data=(x_test,[y_test,y_test_2]),epochs=50)\n",
        "  \n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSM2vIMsyQY3",
        "outputId": "4ec446f4-3007-4f16-8143-e8b4dd0cfbde"
      },
      "source": [
        "model.save(\"model.h5\")\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 198, 198, 140 3920        input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 196, 196, 130 163930      conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 196, 196, 130 520         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 98, 98, 130)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 96, 96, 120)  140520      max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 96, 96, 120)  480         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 48, 48, 120)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 276480)       0           max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 128)          35389568    flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_59 (Dense)                (None, 80)           10320       dense_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 128)          35389568    flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_60 (Dense)                (None, 64)           5184        dense_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_55 (Dense)                (None, 64)           8256        dense_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_61 (Dense)                (None, 32)           2080        dense_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_56 (Dense)                (None, 32)           2080        dense_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32)           0           dense_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_57 (Dense)                (None, 1)            33          dense_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_62 (Dense)                (None, 2)            66          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 71,116,525\n",
            "Trainable params: 71,116,025\n",
            "Non-trainable params: 500\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCk9VNimxYZU"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "uEzoClkoblQh",
        "outputId": "9414571b-b6e2-47c1-a821-e1890bb1b510"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "\n",
        "model_path = \"./model.h5\"\n",
        "model = load_model(model_path)\n",
        "output_path = \"\"\n",
        "img_path = \"\"\n",
        "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "pic = cv2.imread(img_path)\n",
        "gray = cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY)\n",
        "faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
        "age_ = []\n",
        "gender_ = []\n",
        "for (x,y,w,h) in faces:\n",
        "  img = gray[y-50:y+40+h,x-10:x+10+w]\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
        "  img = cv2.resize(img,(200,200))\n",
        "  predict = model.predict(np.array(img).reshape(-1,200,200,3))\n",
        "  age_.append(predict[0])\n",
        "  gender_.append(np.argmax(predict[1]))\n",
        "  gend = np.argmax(predict[1])\n",
        "  if gend == 0:\n",
        "    gend = 'Man'\n",
        "    col = (255,0,0)\n",
        "  else:\n",
        "    gend = 'Woman'\n",
        "    col = (203,12,255)\n",
        "  cv2.rectangle(pic,(x,y),(x+w,y+h),(0,225,0),4)\n",
        "  cv2.putText(pic,\"Age : \"+str(int(predict[0]))+\" / \"+str(gend),(x,y),cv2.FONT_HERSHEY_SIMPLEX,w*0.005,col,4)\n",
        "pic1 = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(pic1)\n",
        "plt.show() \n",
        "print(age_,gender_)\n",
        "cv2.imwrite(output_path,pic)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-4f7aad5874e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mface_cascade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"haarcascade_frontalface_default.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mage_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    }
  ]
}